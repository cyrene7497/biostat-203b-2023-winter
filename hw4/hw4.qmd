---
title: "Biostat 203B Homework 4"
subtitle: Due Mar 24 @ 11:59PM
author: Cyrene Arputhasamy (UID: 705527395)
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
knitr:
  opts_chunk: 
    cache: false    
    echo: true
    fig.align: 'center'
    fig.width: 6
    fig.height: 4
    message: FALSE
---

Display machine information:
```{r}
#| eval: true
sessionInfo()
```
Load database libraries and the tidyverse frontend:
```{r}
#| eval: true

suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(tidymodels))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(gtsummary))
suppressPackageStartupMessages(library(GGally))
suppressPackageStartupMessages(library(kernlab))
```

## Predicting 30-day mortality

Using the ICU cohort `icu_cohort.rds` you built in Homework 3, develop at least three analytic approaches for predicting the 30-day mortality of patients admitted to ICU using demographic information (gender, age, marital status, ethnicity), first lab measurements during ICU stay, and first vital measurements during ICU stay. For example, you can use (1) logistic regression with elastic net (lasso + ridge) penalty (e.g., glmnet or keras package), (2) random forest, (3) boosting, and (4) support vector machines, or (5) MLP neural network (keras package)
```{r}
icu_cohort <- readRDS("icu_cohort.rds") %>%
  select(
    -subject_id,
    -intime,
    -hadm_id,
    -stay_id,
    -last_careunit,
    -outtime,
    -los,
    -admittime,
    -dischtime,
    -deathtime,
    -discharge_location,
    -edregtime,
    -edouttime,
    -hospital_expire_flag,
    -anchor_age,
    -anchor_year,
    -anchor_year_group,
    -dod,
    -hadm_to_death)
icu_cohort %>% tbl_summary(by = thirty_day_mort)
```
```{r}
cat_features <- c("first_careunit", "admission_type", "insurance","ethnicity",
                  "gender")
num_features <- c("age_hadm", "wbc", "glucose","heart_rate", "respiratory_rate")
features <- c(cat_features, num_features)
```
```{r}
icu_tbl <- icu_cohort %>%
  select(features, thirty_day_mort) %>%
  print(width = Inf)
icu_tbl$first_careunit <- fct_lump_prop(icu_tbl$first_careunit, prop = 0.15, w = NULL, other_level = "Other")
icu_tbl$admission_type <- fct_lump_prop(icu_tbl$admission_type, prop = 0.10, w = NULL, other_level = "Other")
icu_tbl$ethnicity <- fct_lump_prop(icu_tbl$ethnicity, prop = 0.04, w = NULL, other_level = "Other")
icu_tbl$thirty_day_mort <- as.factor(icu_tbl$thirty_day_mort)
tbl_summary(icu_tbl, by = thirty_day_mort)
```


```{r}
icu_tbl %>% ggpairs(columns = 1:5, ggplot2::aes(colour = thirty_day_mort))
icu_tbl %>% ggpairs(columns = 6:10, ggplot2::aes(colour = thirty_day_mort))
```

1. Partition data into 50% training set and 50% test set. Stratify partitioning according the 30-day mortality status.
```{r}
set.seed(203)
    
data_split <- initial_split(
  icu_tbl,
  #stratify by `thirty_day_mort`
  prop = 0.5
)
data_split
```

```{r}
icu_other <- training(data_split)
dim(icu_other)
icu_test <- testing(data_split)
dim(icu_test)
```


2. Train and tune the models using the training set.
```{r}
#Random Forest Recipe
rf_recipe <- recipe(
  thirty_day_mort ~.,
  data = icu_other
) %>%
  #mode imputation for ethnicity (categorical) for missing/`Unknown` values
  step_impute_mode(ethnicity) %>%
  # mean imputation for `wbc`, `glucose`, `heart_rate`, and `respiratory rate`
  # which have some but not many missing/unknown values
  step_impute_mean(wbc) %>%
  step_impute_mean(glucose) %>%
  step_impute_mean(heart_rate) %>%
  step_impute_mean(respiratory_rate) %>%
  # zero-variance filter on numerical predictors
  step_zv(all_numeric_predictors()) %>%
  # step_dummy(all_nominal()) %>%
  # step_normalize(all_numeric_predictors()) %>%
  step_impute_linear(all_numeric_predictors()) %>%
  prep(training = icu_other, retrain = TRUE)
rf_recipe
```
```{r}
#Random Forest Model
rf_mod <- rand_forest(
  mode = "classification",
  mtry = tune(),
  trees = tune()
) %>%
  set_engine("ranger")
rf_mod
```
```{r}
#Random Forest workflow
rf_wf <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_mod)
rf_wf
```
```{r}
#Random Forest Tuning
param_grid_rf <- grid_regular(
  trees(range = c(100L, 300L)),
  mtry(range = c(1L, 5L)),
  levels = c(3, 5)
)
param_grid_rf
```
```{r}
#RF Cross Validation
set.seed(203)
folds <- vfold_cv(icu_other, v = 3)
folds

#Fit cross validation
rf_fit <- rf_wf %>%
  tune_grid(
    resamples = folds,
    grid = param_grid_rf,
    metrics = metric_set(roc_auc, accuracy)
  )
rf_fit
```
```{r}
#Visualize CV results
rf_fit %>% collect_metrics() %>%
  print(width = Inf) %>%
  filter(.metric == "roc_auc") %>%
  ggplot(mapping = aes(x = trees, y = mean, color = mtry)) +
  geom_point()

rf_fit %>% show_best("roc_auc")

best_rf <- rf_fit %>% 
  select_best("roc_auc")
best_rf
```
```{r}
#Logistical Recipe
logi_recipe <-
  recipe(
    thirty_day_mort ~ .,
    data = icu_other
  ) %>% 
  #mode imputation for ethnicity (categorical) for missing/`Unknown` values
  step_impute_mode(ethnicity) %>%
  # mean imputation for `wbc`, `glucose`, `heart_rate`, and `respiratory rate`
  # which have some but not many missing/unknown values
  step_impute_mean(wbc) %>%
  step_impute_mean(glucose) %>%
  step_impute_mean(heart_rate) %>%
  step_impute_mean(respiratory_rate) %>%
  # zero-variance filter on numerical predictors
  step_zv(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_numeric_predictors()) %>%
  prep(training = icu_other, retrain = TRUE)
logi_recipe
```
```{r}
#Logistic Model
logi_model <- 
  logistic_reg(
   penalty = tune(),
   mixture = tune()
  ) %>%
  set_engine("glmnet", standardize = FALSE)
logi_model
```
```{r}
#Logistic Workflow
logi_wf <- workflow() %>%
  add_recipe(logi_recipe) %>%
  add_model(logi_model)
logi_wf
```
```{r}
#Logistic Tuning grid
param_grid_l <- grid_regular(
  penalty(range = c(-6,3)),
  mixture(),
  levels = c(100, 5)
)
param_grid_l
```
```{r}
#Logistic Cross Validation using same folds as RF

logi_fit <- logi_wf %>%
  tune_grid(
    resamples = folds,
    grid = param_grid_l,
    metrics = metric_set(roc_auc, accuracy)
  )
logi_fit
```
```{r}
#Visualize Logistic Regression Results

logi_fit %>%
  collect_metrics() %>%
  print(width = Inf) %>%
  filter(.metric == "roc_auc") %>%
  ggplot(mapping = aes(x = penalty, y = mean, color = mixture)) +
  geom_point() +
  labs(x = "Penalty", y = "CV AUC") +
  scale_x_log10()
```
```{r}
#Top 5 Logistic Models
logi_fit %>%
  show_best("roc_auc")

#Select the best
best_logi <- logi_fit %>%
  select_best("roc_auc")
best_logi
```
```{r}
#SVM with RBF Kernel Recipe
svm_recipe <- recipe(
  thirty_day_mort ~ .,
  data = icu_other
) %>%
  #mode imputation for ethnicity (categorical) for missing/`Unknown` values
  step_impute_mode(ethnicity) %>%
  # mean imputation for `wbc`, `glucose`, `heart_rate`, and `respiratory rate`
  # which have some but not many missing/unknown values
  step_impute_mean(wbc) %>%
  step_impute_mean(glucose) %>%
  step_impute_mean(heart_rate) %>%
  step_impute_mean(respiratory_rate) %>%
  # zero-variance filter on numerical predictors
  step_zv(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_numeric_predictors()) %>%
  prep(training = icu_other, retrain = TRUE)
svm_recipe

#SVM Model
svm_model <- svm_rbf(
  mode = "classification",
  cost = tune(),
  rbf_sigma = tune()
) %>% set_engine("kernlab")
svm_model

#SVM Workflow

svm_wf <- workflow() %>%
  add_recipe(svm_recipe) %>%
  add_model(svm_model)
svm_wf

#SVM Tuning Grid

param_grid_svm <- grid_regular(
  cost(range = c(-8, 5)), 
  rbf_sigma(range = c(-5, -3)),
  levels = c(14, 5)
)
param_grid_svm
```
```{r}
#SVM Cross Validation

svm_fit <- svm_wf %>%
  tune_grid(
    resamples = folds,
    metrics = metric_set(roc_auc, accuracy)
  )
svm_fit
```
```{r}
#Visualize SVM CV Results
svm_fit %>%
  collect_metrics() %>%
  print(width = Inf) %>%
  filter(.metric == "roc_auc") %>% 
  ggplot(mapping = aes(x = cost, y = mean, alpha = rbf_sigma)) + 
  geom_point() + 
  labs(x = "Cost", y = "CV AUC") + scale_x_log10()
```
```{r}
#Show top 5 SVM Models
svm_fit %>%
  show_best("roc_auc")

#Select best SVM model
best_svm <- svm_fit %>%
  select_best("roc_auc")
best_svm
```

3. Compare model classification performance on the test set. Report both the area under ROC curve and accuracy for each model.
```{r}
#Final RF workflow
final_wf <- rf_wf %>%
  finalize_workflow(best_rf)
final_wf

final_fit_rf <- final_wf %>%
  last_fit(data_split)
final_fit_rf

final_fit_rf %>% collect_metrics()
```
```{r}
#Final Logistic Workflow
final_wf_l <- logi_wf %>%
  finalize_workflow(best_logi)
final_wf_l

#Fit the whole training set, then predict the test cases
final_fit_l <- final_wf_l %>%
  last_fit(data_split)
final_fit_l

#Test metrics
final_fit_l %>% collect_metrics()
```
```{r}
#Final SVM Workflow
final_wf_svm <- svm_wf %>%
  finalize_workflow(best_svm)
final_wf_svm

#Fit the whole training set with SVM, then predict
final_fit_svm <- final_wf_svm %>%
  last_fit(data_split)
final_fit_svm

#Test Metrics
final_fit_svm %>%
  collect_metrics()
```

